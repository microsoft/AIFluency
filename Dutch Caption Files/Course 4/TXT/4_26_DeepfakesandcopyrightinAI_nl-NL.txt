Stel je voor dat je door je
mobiele telefoon bladert,

en dat je een video tegenkomt
van een beroemd iemand

die iets controversieels zegt.

Je bent verbijsterd,
maar dan herinner je je:

het zou een deepfake kunnen zijn.

Een deepfake is
frauduleuze inhoud,

meestal audio of video,

die is gemanipuleerd
of gecreëerd

met behulp van kunstmatige intelligentie.

Deepfakes gebruiken
geavanceerde AI-technieken

om de stem en/of afbeelding
van een bestaand iemand

te vervangen door griezelig gelijkende
kunstmatige evenbeelden.

Deze technologie heeft het
steeds moeilijker gemaakt

om te onderscheiden of iets wat je ziet
of hoort op het internet echt is.

Deepfakes worden vaak gebruikt
om desinformatie te verspreiden

en kan worden gebruikt
bij oplichting, verkiezingsmanipulatie,

social engineering-aanvallen
en andere vormen van fraude.

Het besef dat het bestrijden
van deepfakes dringend nodig is,

heeft de technologiesector, waaronder
bedrijven die AI-modellen helpen ontwikkelen

en diensten voor de consument
zoals Microsoft,

ertoe aangezet maatregelen te nemen.

Deze inspanningen hebben zich
in de loop der tijd verder ontwikkeld,

van het invoeren van
voorzieningen tegen namaak

tot het bevorderen van digitale
beschermingstechnologieën.

Dit is wat de tech-sector
doet:

1. Een veilige omgeving opbouwen:

Er worden veiligheidsmaatregelen
genomen om ervoor te zorgen dat

alles soepel en veilig verloopt.

Dit omvat dingen
als voortdurende controles,

slecht gedrag blokkeren
en snel maatregelen nemen

tegen mensen die het systeem misbruiken.

2. Verificatie van de inhoud:

Om onechte video's, afbeeldingen
of audio te bestrijden,

worden er speciale markeringen of
symbolen toegevoegd aan AI-gecreëerde inhoud.

Dit helpt bij het bepalen van

de oorsprong en geschiedenis
van de inhoud.

3. Diensten veilig houden:

Er worden inspanningen gedaan om
schadelijke en misleidende inhoud

te herkennen en van
online platforms te verwijderen.

Dit zorgt ervoor dat de online ruimte
voor iedereen veilig en respectvol blijft.

4. Samenwerken:

Net zoals samenwerking de sleutel is
tot het bereiken van gedeelde doelen,

kunnen mensen
in de technologie-industrie,

organisaties
toegewijd aan maatschappelijk welzijn

en overheidsinstanties
die samenkomen,

collectief bijdragen

aan het creëren van een
veiligere online omgeving.

Deze geïntegreerde aanpak

kan leiden tot innovatieve oplossingen
en sterkere bescherming

voor iedereen in de digitale ruimte.

5. Wetten aanpassen aan nieuwe uitdagingen:

Naarmate zich nieuwe uitdagingen voordoen,

worden er inspanningen geleverd
om nieuwe wetten en initiatieven te ontwikkelen

om mensen tegen misbruik te beschermen.

6. Het publiek voorlichten:

Het is belangrijk voor iedereen
om goed geïnformeerd te zijn.

Er zijn initiatieven gaande
om mensen in staat te stellen

echte inhoud te onderscheiden
van valse inhoud.

Dit omvat de ontwikkeling
van nieuwe hulpmiddelen

en educatieve programma's
voor het publiek.

Deze strategieën zijn erop gericht
de dingen transparanter

en de samenleving weerbaarder
te maken tegen deepfakes.

Hoewel deepfakes
ethische en veiligheidsproblemen opleveren

vanwege hun potentiële misbruik
en het verspreiden van desinformatie

en imitatie,

boekt AI-technologie ook vooruitgang
in het met hoge nauwkeurigheid

detecteren van deepfakes.

Dit brengt ons bij
een ander belangrijk onderwerp:

de opkomst en bewustwording
van AI-gegenereerde inhoud.

Auteursrecht is een juridisch concept

dat makers en auteurs
van origineel werk

de exclusieve rechten verschaft
op het gebruik en de distributie ervan,

ervoor zorgend dat ze erkenning krijgen
en financieel voordeel hebben

van hun creaties.

Maar wat gebeurt er
als de maker AI is?

Door het besef dat auteursrecht
een belangrijk onderwerp is

om aan te pakken
voor AI-gegenereerde inhoud,

zijn er initiatieven ontwikkeld zoals de
Microsoft Copilot Copyright Commitment

om bestaande beveiligingsondersteuning

voor intellectueel eigendom
uit te breiden naar

commerciële Copilot-diensten.

Deze bereidheid gaat in op de mogelijke
aansprakelijkheid voor inbreuk op

intellectuele eigendomsrechten die
zouden kunnen voortvloeien uit

het gebruik van de resultaten van
Microsoft Copilot en de Azure OpenAI-dienst.

Om het vertrouwen
in AI-gegenereerde inhoud

verder te vergroten heeft Microsoft
verificatie van inhoud ontwikkeld.

Deze voorziening
gebruikt cryptografische methoden

om een onzichtbaar digitaal watermerk
toe te voegen aan

alle AI-gegenereerde afbeeldingen in Bing,

inclusief de tijd en datum waarop
ze oorspronkelijk zijn aangemaakt.

Dit helpt bij het bepalen
waar de inhoud vandaankomt

en geeft degenen
die inhoud maken en delen

betere hulpmiddelen
om te beslissen wat te vertrouwen is.

Dit is een cruciale stap
om ervoor te zorgen

dat we AI-technologie op een veilige
en verantwoorde manier gebruiken.

Het is belangrijk om op de hoogte te blijven.

Onthoud dat niet alles
wat je ziet of hoort de waarheid is,

dus als het gaat om
AI-gegenereerde inhoud

is het belangrijk om je rechten te kennen

en de maatregelen die zijn getroffen
om ze te beschermen.