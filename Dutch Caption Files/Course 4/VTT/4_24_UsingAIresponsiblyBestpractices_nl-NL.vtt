WEBVTT

00:00:03.083 --> 00:00:06.000
Naarmate AI zich meer en meer
in ons leven integreert,

00:00:06.167 --> 00:00:09.917
is het belangrijk om ons af te vragen hoe we
ervoor zorgen dat het verantwoord wordt gebruikt?

00:00:11.083 --> 00:00:12.083
Laten we dit eens nader bekijken.

00:00:13.042 --> 00:00:15.417
AI begrijpen
is de eerste stap.

00:00:16.208 --> 00:00:17.542
Het is niet alleen een modewoord,

00:00:17.708 --> 00:00:19.750
het is een tool met allerlei mogelijkheden

00:00:19.917 --> 00:00:22.208
en het is belangrijk
de basisprincipes ervan te begrijpen.

00:00:23.458 --> 00:00:26.000
Op de hoogte blijven
van de nieuwste ontwikkelingen

00:00:26.167 --> 00:00:28.875
en ethische discussies
op het gebied van AI is essentieel.

00:00:30.083 --> 00:00:33.417
Deze kennis is de sleutel om AI
op een verantwoorde manier te gebruiken.

00:00:34.542 --> 00:00:37.292
AI kan net als wij
blinde vlekken hebben.

00:00:38.458 --> 00:00:42.458
Het kan maatschappelijke vooroordelen vertonen
die aanwezig zijn in de data waarvan het leert.

00:00:43.542 --> 00:00:46.083
Door actief op zoek te gaan naar
onbevooroordeelde informatie

00:00:46.250 --> 00:00:48.958
en te begrijpen hoe AI data gebruikt,

00:00:49.125 --> 00:00:51.667
wordt het navigeren
door deze blinde vlekken gemakkelijker.

00:00:52.042 --> 00:00:55.500
Deze aanpak kan ook helpen de vertekening
van machine learning te verminderen.

00:00:56.875 --> 00:00:58.708
Veiligheid komt altijd op de eerste plaats.

00:00:59.250 --> 00:01:00.458
Jouw data is kostbaar

00:01:00.625 --> 00:01:03.667
en je moet weten hoe deze
door AI-systemen wordt gebruikt.

00:01:04.708 --> 00:01:07.500
Kies diensten die waarde hechten
aan de privacy van gebruikers.

00:01:07.875 --> 00:01:11.708
De beste AI-systemen geven prioriteit aan
veiligheid en transparantie.

00:01:13.000 --> 00:01:14.792
Microsoft neemt extra maatregelen

00:01:14.958 --> 00:01:17.500
om ervoor te zorgen dat jouw data
veilig en beschermd zijn.

00:01:18.542 --> 00:01:21.750
Zo worden aan het einde
van een chatsessie in Copilot

00:01:21.917 --> 00:01:24.083
de prompts en antwoorden
gewist.

00:01:25.417 --> 00:01:27.625
Ook worden de data
van jouw organisatie

00:01:27.792 --> 00:01:29.833
zonder jouw toestemming
niet gedeeld met derden.

00:01:31.000 --> 00:01:34.292
Jouw persoonlijke gegevens
moeten tenslotte persoonlijk blijven.

00:01:35.208 --> 00:01:37.625
Als het gaat om
AI-gegenereerde inhoud,

00:01:37.792 --> 00:01:40.708
is het essentieel om het niet
zomaar voor waar aan te nemen.

00:01:41.750 --> 00:01:44.500
Streef er altijd naar
om informatie te verifiëren

00:01:44.667 --> 00:01:46.167
uit verschillende bronnen

00:01:46.333 --> 00:01:48.458
en je vermogen
tot kritisch denken te gebruiken.

00:01:49.042 --> 00:01:53.375
Kritisch denken kan helpen bij het evalueren
en verbeteren van AI-gegenereerde inhoud.

00:01:54.042 --> 00:01:56.917
Je kunt dit doen door
feiten en bronnen te verifiëren,

00:01:57.083 --> 00:01:59.917
de doelen van de inhoud
en de doelgroep te begrijpen

00:02:00.292 --> 00:02:02.542
en verschillende gezichtspunten
in overweging te nemen.

00:02:03.417 --> 00:02:06.083
Het is ook belangrijk om ervoor te zorgen
dat de AI-tool die je gebruikt

00:02:06.292 --> 00:02:09.792
duidelijke beleidsregels
en richtlijnen heeft

00:02:09.958 --> 00:02:11.083
voor het veilige gebruik ervan.

00:02:11.833 --> 00:02:13.792
Een goed geïnformeerde gebruiker

00:02:14.042 --> 00:02:16.500
is tenslotte de beste verdediging
tegen onjuiste informatie.

00:02:17.583 --> 00:02:19.292
AI kan een kracht ten goede zijn.

00:02:19.625 --> 00:02:21.292
Het kan ons helpen in de gezondheidszorg,

00:02:21.458 --> 00:02:24.500
het onderwijs en zelfs
bij milieubescherming.

00:02:26.167 --> 00:02:28.167
Het 'AI for Good'-initiatief van Microsoft

00:02:28.333 --> 00:02:32.000
is ontworpen om mensen
en organisaties wereldwijd

00:02:32.167 --> 00:02:35.042
uit te rusten met het vermogen
humanitaire uitdagingen aan te pakken

00:02:35.208 --> 00:02:38.542
en een wereld te bevorderen die
duurzamer en inclusiever is.

00:02:39.417 --> 00:02:42.042
Denk bijvoorbeeld eens aan
AI for Good Lab.

00:02:42.500 --> 00:02:45.000
Het maakt gebruik van AI
om over de hele wereld

00:02:45.167 --> 00:02:47.542
gemeenschappen te identificeren
die extra steun nodig hebben,

00:02:47.958 --> 00:02:50.792
vooral degenen die risico lopen
door natuurrampen

00:02:50.958 --> 00:02:52.500
zoals overstromingen of aardbevingen.

00:02:52.792 --> 00:02:55.125
Door te bepalen waar
deze gemeenschappen zich bevinden

00:02:55.292 --> 00:02:57.875
kunnen vitale hulpmiddelen
snel worden ingezet

00:02:58.042 --> 00:02:59.375
om hun welzijn veilig te stellen.

00:03:00.000 --> 00:03:02.292
Daarnaast heeft het Fred Hutch Cancer Center,
in samenwerking met Microsoft,

00:03:02.917 --> 00:03:07.500
het potentieel van AI aangeboord
om QuitBot te ontwikkelen.

00:03:08.458 --> 00:03:10.958
Deze chatbot biedt hulp
op maat

00:03:11.125 --> 00:03:13.500
aan mensen die vastbesloten zijn
om te stoppen met roken.

00:03:14.083 --> 00:03:16.125
AI moet een hulpmiddel voor het goede zijn,

00:03:16.292 --> 00:03:19.375
nooit een middel om onjuiste informatie
te verspreiden of schade te berokkenen.

00:03:20.625 --> 00:03:22.000
Wat kun je nog meer doen?

00:03:22.458 --> 00:03:23.917
Neem deel aan het gesprek.

00:03:24.625 --> 00:03:27.417
Start discussies
in je gemeenschap en op je werk.

00:03:28.042 --> 00:03:32.583
Informeer naar het beleid voor
verantwoord gebruik van AI-diensten.

00:03:33.167 --> 00:03:36.375
Moedig mensen aan om na te denken
over hoe AI wordt gebruikt

00:03:36.542 --> 00:03:38.750
en om maatregelen te nemen
om misbruik te voorkomen.

00:03:39.667 --> 00:03:41.500
Door deel te nemen aan deze gesprekken,

00:03:41.792 --> 00:03:45.042
kun je helpen ervoor te zorgen dat AI
verantwoord wordt gebruikt.

00:03:45.625 --> 00:03:48.375
Samen kunnen we vorm geven
aan de toekomst van AI.

00:03:49.125 --> 00:03:51.708
Laten we zorgen dat het een toekomst is
waar we allemaal trots op kunnen zijn.