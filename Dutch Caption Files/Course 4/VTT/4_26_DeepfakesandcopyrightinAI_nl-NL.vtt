WEBVTT

00:00:03.625 --> 00:00:05.958
Stel je voor dat je door je
mobiele telefoon bladert,

00:00:06.042 --> 00:00:08.583
en dat je een video tegenkomt
van een beroemd iemand

00:00:08.667 --> 00:00:10.542
die iets controversieels zegt.

00:00:11.125 --> 00:00:13.292
Je bent verbijsterd,
maar dan herinner je je:

00:00:13.375 --> 00:00:15.083
het zou een deepfake kunnen zijn.

00:00:15.792 --> 00:00:18.375
Een deepfake is
frauduleuze inhoud,

00:00:18.458 --> 00:00:20.125
meestal audio of video,

00:00:20.292 --> 00:00:22.458
die is gemanipuleerd
of gecreëerd

00:00:22.542 --> 00:00:24.250
met behulp van kunstmatige intelligentie.

00:00:25.208 --> 00:00:27.750
Deepfakes gebruiken
geavanceerde AI-technieken

00:00:27.833 --> 00:00:30.958
om de stem en/of afbeelding
van een bestaand iemand

00:00:31.042 --> 00:00:33.583
te vervangen door griezelig gelijkende
kunstmatige evenbeelden.

00:00:34.750 --> 00:00:37.458
Deze technologie heeft het
steeds moeilijker gemaakt

00:00:37.542 --> 00:00:40.917
om te onderscheiden of iets wat je ziet
of hoort op het internet echt is.

00:00:41.667 --> 00:00:44.958
Deepfakes worden vaak gebruikt
om desinformatie te verspreiden

00:00:45.083 --> 00:00:48.208
en kan worden gebruikt
bij oplichting, verkiezingsmanipulatie,

00:00:48.375 --> 00:00:51.208
social engineering-aanvallen
en andere vormen van fraude.

00:00:52.208 --> 00:00:55.250
Het besef dat het bestrijden
van deepfakes dringend nodig is,

00:00:55.333 --> 00:00:59.708
heeft de technologiesector, waaronder
bedrijven die AI-modellen helpen ontwikkelen

00:00:59.792 --> 00:01:02.250
en diensten voor de consument
zoals Microsoft,

00:01:02.333 --> 00:01:03.375
ertoe aangezet maatregelen te nemen.

00:01:03.917 --> 00:01:06.042
Deze inspanningen hebben zich
in de loop der tijd verder ontwikkeld,

00:01:06.250 --> 00:01:09.583
van het invoeren van
voorzieningen tegen namaak

00:01:09.667 --> 00:01:12.250
tot het bevorderen van digitale
beschermingstechnologieën.

00:01:12.750 --> 00:01:14.417
Dit is wat de tech-sector
doet:

00:01:14.958 --> 00:01:16.875
1. Een veilige omgeving opbouwen:

00:01:17.167 --> 00:01:19.458
Er worden veiligheidsmaatregelen
genomen om ervoor te zorgen dat

00:01:19.542 --> 00:01:21.708
alles soepel en veilig verloopt.

00:01:22.708 --> 00:01:25.292
Dit omvat dingen
als voortdurende controles,

00:01:25.500 --> 00:01:27.833
slecht gedrag blokkeren
en snel maatregelen nemen

00:01:27.917 --> 00:01:30.042
tegen mensen die het systeem misbruiken.

00:01:31.083 --> 00:01:32.792
2. Verificatie van de inhoud:

00:01:33.000 --> 00:01:36.125
Om onechte video's, afbeeldingen
of audio te bestrijden,

00:01:36.750 --> 00:01:41.042
worden er speciale markeringen of
symbolen toegevoegd aan AI-gecreëerde inhoud.

00:01:41.792 --> 00:01:42.792
Dit helpt bij het bepalen van

00:01:42.875 --> 00:01:45.083
de oorsprong en geschiedenis
van de inhoud.

00:01:45.708 --> 00:01:47.417
3. Diensten veilig houden:

00:01:47.833 --> 00:01:50.042
Er worden inspanningen gedaan om
schadelijke en misleidende inhoud

00:01:50.125 --> 00:01:53.167
te herkennen en van
online platforms te verwijderen.

00:01:53.833 --> 00:01:57.458
Dit zorgt ervoor dat de online ruimte
voor iedereen veilig en respectvol blijft.

00:01:58.458 --> 00:02:00.000
4. Samenwerken:

00:02:00.292 --> 00:02:04.167
Net zoals samenwerking de sleutel is
tot het bereiken van gedeelde doelen,

00:02:04.375 --> 00:02:06.375
kunnen mensen
in de technologie-industrie,

00:02:06.458 --> 00:02:09.250
organisaties
toegewijd aan maatschappelijk welzijn

00:02:09.458 --> 00:02:11.542
en overheidsinstanties
die samenkomen,

00:02:11.750 --> 00:02:13.667
collectief bijdragen

00:02:13.750 --> 00:02:16.167
aan het creëren van een
veiligere online omgeving.

00:02:16.917 --> 00:02:18.375
Deze geïntegreerde aanpak

00:02:18.458 --> 00:02:21.583
kan leiden tot innovatieve oplossingen
en sterkere bescherming

00:02:21.667 --> 00:02:23.292
voor iedereen in de digitale ruimte.

00:02:24.083 --> 00:02:26.917
5. Wetten aanpassen aan nieuwe uitdagingen:

00:02:27.125 --> 00:02:28.625
Naarmate zich nieuwe uitdagingen voordoen,

00:02:28.708 --> 00:02:31.417
worden er inspanningen geleverd
om nieuwe wetten en initiatieven te ontwikkelen

00:02:31.500 --> 00:02:33.042
om mensen tegen misbruik te beschermen.

00:02:33.542 --> 00:02:35.250
6. Het publiek voorlichten:

00:02:35.333 --> 00:02:37.708
Het is belangrijk voor iedereen
om goed geïnformeerd te zijn.

00:02:38.625 --> 00:02:41.042
Er zijn initiatieven gaande
om mensen in staat te stellen

00:02:41.125 --> 00:02:43.917
echte inhoud te onderscheiden
van valse inhoud.

00:02:44.958 --> 00:02:47.417
Dit omvat de ontwikkeling
van nieuwe hulpmiddelen

00:02:47.500 --> 00:02:49.625
en educatieve programma's
voor het publiek.

00:02:50.833 --> 00:02:53.917
Deze strategieën zijn erop gericht
de dingen transparanter

00:02:54.000 --> 00:02:57.250
en de samenleving weerbaarder
te maken tegen deepfakes.

00:02:57.750 --> 00:03:01.042
Hoewel deepfakes
ethische en veiligheidsproblemen opleveren

00:03:01.250 --> 00:03:04.208
vanwege hun potentiële misbruik
en het verspreiden van desinformatie

00:03:04.292 --> 00:03:05.458
en imitatie,

00:03:05.833 --> 00:03:09.292
boekt AI-technologie ook vooruitgang
in het met hoge nauwkeurigheid

00:03:09.375 --> 00:03:10.500
detecteren van deepfakes.

00:03:11.000 --> 00:03:13.250
Dit brengt ons bij
een ander belangrijk onderwerp:

00:03:13.458 --> 00:03:16.458
de opkomst en bewustwording
van AI-gegenereerde inhoud.

00:03:17.167 --> 00:03:19.167
Auteursrecht is een juridisch concept

00:03:19.250 --> 00:03:21.958
dat makers en auteurs
van origineel werk

00:03:22.042 --> 00:03:24.583
de exclusieve rechten verschaft
op het gebruik en de distributie ervan,

00:03:24.792 --> 00:03:27.917
ervoor zorgend dat ze erkenning krijgen
en financieel voordeel hebben

00:03:28.000 --> 00:03:29.125
van hun creaties.

00:03:29.583 --> 00:03:33.125
Maar wat gebeurt er
als de maker AI is?

00:03:33.792 --> 00:03:36.875
Door het besef dat auteursrecht
een belangrijk onderwerp is

00:03:36.958 --> 00:03:38.708
om aan te pakken
voor AI-gegenereerde inhoud,

00:03:38.917 --> 00:03:42.542
zijn er initiatieven ontwikkeld zoals de
Microsoft Copilot Copyright Commitment

00:03:42.708 --> 00:03:44.125
om bestaande beveiligingsondersteuning

00:03:44.208 --> 00:03:47.083
voor intellectueel eigendom
uit te breiden naar

00:03:47.167 --> 00:03:49.083
commerciële Copilot-diensten.

00:03:49.583 --> 00:03:53.375
Deze bereidheid gaat in op de mogelijke
aansprakelijkheid voor inbreuk op

00:03:53.458 --> 00:03:55.667
intellectuele eigendomsrechten die
zouden kunnen voortvloeien uit

00:03:55.750 --> 00:03:59.125
het gebruik van de resultaten van
Microsoft Copilot en de Azure OpenAI-dienst.

00:03:59.625 --> 00:04:02.458
Om het vertrouwen
in AI-gegenereerde inhoud

00:04:02.667 --> 00:04:05.333
verder te vergroten heeft Microsoft
verificatie van inhoud ontwikkeld.

00:04:06.042 --> 00:04:08.417
Deze voorziening
gebruikt cryptografische methoden

00:04:08.500 --> 00:04:10.792
om een onzichtbaar digitaal watermerk
toe te voegen aan

00:04:10.875 --> 00:04:13.292
alle AI-gegenereerde afbeeldingen in Bing,

00:04:13.542 --> 00:04:16.542
inclusief de tijd en datum waarop
ze oorspronkelijk zijn aangemaakt.

00:04:17.167 --> 00:04:19.458
Dit helpt bij het bepalen
waar de inhoud vandaankomt

00:04:19.750 --> 00:04:22.125
en geeft degenen
die inhoud maken en delen

00:04:22.208 --> 00:04:24.250
betere hulpmiddelen
om te beslissen wat te vertrouwen is.

00:04:25.042 --> 00:04:28.875
Dit is een cruciale stap
om ervoor te zorgen

00:04:28.958 --> 00:04:30.792
dat we AI-technologie op een veilige
en verantwoorde manier gebruiken.

00:04:31.208 --> 00:04:33.125
Het is belangrijk om op de hoogte te blijven.

00:04:33.750 --> 00:04:37.208
Onthoud dat niet alles
wat je ziet of hoort de waarheid is,

00:04:37.292 --> 00:04:39.792
dus als het gaat om
AI-gegenereerde inhoud

00:04:40.000 --> 00:04:41.708
is het belangrijk om je rechten te kennen

00:04:41.792 --> 00:04:43.875
en de maatregelen die zijn getroffen
om ze te beschermen.